
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>音乐乐器声音分类 - 名字</title>
  <meta name="author" content="小逸">

  
  <meta name="description" content="音乐分类其实很早就有人做了，这些天在kaggle上有个Million Song Dataset Challenge 非常火，上面有大量的数据可以让选手们通过底层，高层的和基于用户协作推荐的等等手段来对歌曲进行推荐. 这里我做的音乐声音分类是底层的, 而且我觉得一般的音乐文件要处理的东西太多了，节奏 &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://kkx.github.com/blog/2012/05/21/yin-le-le-qi-sheng-yin-fen-lei">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="名字" type="application/atom+xml">
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-31462157-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<script type="text/javascript"
        src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
      MathJax.InputJax.TeX.prefilterHooks.Add(function (data) {
    data.math = data.math.replace(/^\s*<!\[CDATA\[\s*((?:\n|.)*)\s*\]\]>\s*$/m,"$1");
});
});
</script>

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">名字</a></h1>
  
    <h2>没想好</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:kkx.github.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/about/">About me</a></li>
  <li><a href="/plan/">Plans</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">音乐乐器声音分类</h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-05-21T23:07:00-07:00" pubdate data-updated="true">May 21<span>st</span>, 2012</time>
        
         | <a href="#disqus_thread">Comments</a>
        
      </p>
    
  </header>


<div class="entry-content"><p>音乐分类其实很早就有人做了，这些天在kaggle上有个<a href="http://www.kaggle.com/c/msdchallenge">Million Song Dataset Challenge</a> 非常火，上面有大量的数据可以让选手们通过底层，高层的和基于用户协作推荐的等等手段来对歌曲进行推荐. 这里我做的音乐声音分类是底层的, 而且我觉得一般的音乐文件要处理的东西太多了，节奏，速度什么的，在这里我只对4种乐器的声音进行分类: 钢琴，吉他，口琴，小提琴。</p>

<p>一般底层的声音，语音分类，speech recognition 使用无外乎<a href="MFCC">Mel-frequency cepstrum</a> 和 lpc analysis。 第二是个比较老的方法，而MFCC是我所用到的。可以把MFCCs对于好分类和识别的家伙们来说可以理解为对一段声音文件的descriptor，重点是这个descriptor非常discriminant. 在实验中，使用了matlab的voicebox里的melcepst函数，可以生成长度为12的数组，每个数组一般是一很小段声音的description，由于取样和设置的问题，MFCC所包含的声音长度是不一样的，在我的实验中，差不多连续1000个MFCC差不多是6秒钟的音频。 那4种声音来源分别是verycd上名家solo哈，不过要吐槽的是找了好多title是solo的，但是其实是是几种乐器和音的。每个类里取了6首左右的歌曲(20分钟左右)作为训练数据，提取出500k的MFCCs。</p>

<p>在实验中我使用了两个方法, 一种是在学校里老师讲的”常规”方法, 还有一种是用于图像分类的。总觉得在做底层分类的时候，图像识别和声音识别的步骤是差不多的。</p>

<ul>
  <li>Binary-split, SVM</li>
  <li>Naive Bayes Nearest Neighbor </li>
</ul>

<h2 id="binary-split--svm">Binary-split + SVM</h2>

<p>500k+的数据直接用来使用的话那就太夸张了，Binary-split+SVM这方法简单的来说是通过binary-split把500k的MFCC压缩成1000到2000个clusters，通过binary-split类似的数据会在一个小组里面。这种clustering算法里最有名的是k-means，不过k-means 速度实在是太悲剧了，虽然压缩损耗度要比binary-split少一些。 </p>

<p>通过binary-split数据给压缩到少许clusters里，这所有的clusters其实就是所谓的<a href="http://en.wikipedia.org/wiki/Codebook">codebook</a>。codebook在通讯里面非常用,往往在数据通讯里，特别是声音传输中，需要用到codebook把传输数据进行压缩，在接受点的那一端，通过decode来还原原始数据。像一般的手机通讯就是用到这个概念，所以说很多时候人们发现电话里的声音总不是特别像某个人，原因就是因为声音信息在传输的时候多少给损耗掉了。在实验中，每个声音段(通常是1000个MFCCs也就是6秒左右的声音)用codebook可以生成一个一个histogram: 把每个MFCC在binary-split树里跑一下，找到最相近的cluster，通过统计所有cluster里一个声音段落里不同的MFCCs所出现的次数来生成Histogram。</p>

<p>每个声音段所产生的histrogram就是所要用到用来训练SVM的数据。这里的svm是one-vs-all，所以说将有4个svm会训练出来，每个svm会应对每个类，而每个svm会长生出一个概率值，是只一个声音段是它所对应类的可能性。在测试中往往选取最高的可能性作为音频的class。</p>

<p>在测试中，以上的步骤都差不多，只是，不需要生成codebook，直接使用了就可以。这里要说的是，测试的音频长度不一定需要和训练的音频长度一样，只要每次生成的histogram是归一化的就行了。</p>

<table border="1" cellspacing="30" cellpadding="100">
    <tr>
    <th />
    <th />
    <th> Piano|</th>
    <th>          </th>
    <th> Guitar| </th>
    <th>          </th>
    <th> Violin| </th>
    <th />
    <th> Harmonica| </th>
    </tr>

    <tr>
    <th>Piano|</th>
    <th />
    <th>16</th>
    <th />
    <th>8</th>
    <th />
    <th>0</th>
    <th />
    <th>0</th>
    </tr>

    <tr>
    <th>Guitar|</th>
    <th />
    <th>4</th>
    <th />
    <th>12</th>
    <th />
    <th>20</th>
    <th />
    <th>4</th>
    </tr>
    
    <tr>
    <th>Violin|</th>
    <th />
    <th>0</th>
    <th />
    <th>0</th>
    <th />
    <th>20</th>
    <th />
    <th>4</th>
    </tr>

    <tr>
    <th>Harmonica|</th>
    <th />
    <th>0</th>
    <th />
    <th>0</th>
    <th />
    <th>0</th>
    <th />
    <th>16</th>
    </tr>
</table>

<p><br />
测试的时候每个类有20个case，从结果上来看，钢琴和吉他的识别不是很高，而且他们彼此有着很高互指。其实很大的原因是:当我们用codebook的时候，会对数据进行压缩，很多时候这个压缩会让比较discriminant的数据丢失。在这个实验中，钢琴和吉他的声音是比较相似的。</p>

<p><img class="center" src="http://kkx.github.com/images/histogram1.png" width="650" height="850" />
上面这个图是个histogram的分布图，通过随机选取每个类里的某一个训练的音频段生成的分布图，从途中可以看出，实际上通过codebook之后，吉他和钢琴的数据分布是非常耦合和相似的。所以，实验中对钢琴和吉他的分别度不高也有了依据。</p>

<h2 id="naive-bayes-nearest-neighbornbnn">Naive Bayes Nearest Neighbor(NBNN)</h2>
<p>实际上，在图像识别中，很多时候也是运用到了上面所讲的方法，通过codebook对图像所提取的key-points进行clusterization，之后通过第二层的分类器把codebook产出的histogram数组进行分类。所以我觉得NBNN应该也能运用到声音分类中来。 NBNN是最近以篇叫<a href="http://www.google.es/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;ved=0CFMQFjAA&amp;url=http%3A%2F%2Fwww.wisdom.weizmann.ac.il%2F~irani%2FPAPERS%2FInDefenceOfNN_CVPR08.pdf&amp;ei=d7G6T6yCKaOu0QX5_cD0Aw&amp;usg=AFQjCNGWk0lo_L6AEjgco6PPMUZ0YE-zOQ&amp;sig2=ZvwoYRICPitYbrkseMV8Bw">In Defense of Nearest-Neighbor Based Image Classification</a>的论文中看到的，该论文着重指出，codebook对数据损耗在无训练模型中的影响。 NBNN就是无训练模型(也叫no parametric?)， 优点就是不需要训练。。。还有一个优点是在分类里，NBNN用的是image-class距离，而不是image-image距离，这样的话，intravariance很高的类对它的影响不大。</p>

<p>在论文中如果我们使用的邻近邻居是1的话，算法简化成以下:</p>

<ol>
  <li>Compute MFCCs <script type="math/tex">d_i,...,d_n</script> of the query audio</li>
  <li><script type="math/tex">\forall d_i \forall C</script> compute the NN of <script type="math/tex">d_i</script> in <script type="math/tex">C</script>: <script type="math/tex">NN_C(d_i)</script></li>
  <li><script type="math/tex">C = arg min_c\sum_{i=1}^n</script> <script type="math/tex">\left \|d_i - NN_c(d_i)\right \|^2  </script></li>
</ol>

<p><img class="right" src="http://kkx.github.com/images/kd_tree.png" width="200" height="250" title="kt-tree" />
还有一点要说的是，在寻找最近邻居的时候，计算需求是相当高的，在原文里，作者用的是<a href="http://en.wikipedia.org/wiki/K-d_tree">kd-tree</a>,这样的能很快的找到最近的邻居。在这个实验的时候我用的scipy里kd-tree效率非常慢，后来才发现原来原作者是用的approximate kd-tree. </p>

<p>这个算法虽然简单，但是结果是惊人的不错:
使用所有的训练数据里的mfcc，每个测试音频有2000个MFCC，测试过程相当慢(好几个小时,如果使用approximate kd-tree的话应该能快好几个数量级)</p>

<table border="1" cellspacing="30" cellpadding="100">
    <tr>
    <th />
    <th />
    <th> Piano|</th>
    <th>          </th>
    <th> Guitar| </th>
    <th>          </th>
    <th> Violin| </th>
    <th />
    <th> Harmonica| </th>
    </tr>

    <tr>
    <th>Piano|</th>
    <th />
    <th>20</th>
    <th />
    <th>0</th>
    <th />
    <th>0</th>
    <th />
    <th>0</th>
    </tr>

    <tr>
    <th>Guitar|</th>
    <th />
    <th>0</th>
    <th />
    <th>20</th>
    <th />
    <th>1</th>
    <th />
    <th>0</th>
    </tr>
    
    <tr>
    <th>Violin|</th>
    <th />
    <th>0</th>
    <th />
    <th>0</th>
    <th />
    <th>19</th>
    <th />
    <th>0</th>
    </tr>

    <tr>
    <th>Harmonica|</th>
    <th />
    <th>0</th>
    <th />
    <th>0</th>
    <th />
    <th>0</th>
    <th />
    <th>20</th>
    </tr>
</table>

<p><br />
从数据集里随机在每个类中获取500个MFCC，每个音频400个MFCC</p>

<table border="1" cellspacing="30" cellpadding="100">
    <tr>
    <th />
    <th />
    <th> Piano|</th>
    <th>          </th>
    <th> Guitar| </th>
    <th>          </th>
    <th> Violin| </th>
    <th />
    <th> Harmonica| </th>
    </tr>

    <tr>
    <th>Piano|</th>
    <th />
    <th>20</th>
    <th />
    <th>0</th>
    <th />
    <th>0</th>
    <th />
    <th>0</th>
    </tr>

    <tr>
    <th>Guitar|</th>
    <th />
    <th>0</th>
    <th />
    <th>20</th>
    <th />
    <th>3</th>
    <th />
    <th>0</th>
    </tr>
    
    <tr>
    <th>Violin|</th>
    <th />
    <th>0</th>
    <th />
    <th>0</th>
    <th />
    <th>17</th>
    <th />
    <th>0</th>
    </tr>

    <tr>
    <th>Harmonica|</th>
    <th />
    <th>0</th>
    <th />
    <th>0</th>
    <th />
    <th>0</th>
    <th />
    <th>20</th>
    </tr>
</table>

<p><br />
最后是从每个类的训练数据中随机抽取30个MFCCs，每200个MFCC做音频测试数据的长度,测试数据是每个类40个，总使用的时间几秒而已</p>

<table border="1" cellspacing="30" cellpadding="100">
    <tr>
    <th />
    <th />
    <th> Piano|</th>
    <th>          </th>
    <th> Guitar| </th>
    <th>          </th>
    <th> Violin| </th>
    <th />
    <th> Harmonica| </th>
    </tr>

    <tr>
    <th>Piano|</th>
    <th />
    <th>35</th>
    <th />
    <th>5</th>
    <th />
    <th>2</th>
    <th />
    <th>0</th>
    </tr>

    <tr>
    <th>Guitar|</th>
    <th />
    <th>4</th>
    <th />
    <th>35</th>
    <th />
    <th>1</th>
    <th />
    <th>0</th>
    </tr>
    
    <tr>
    <th>Violin|</th>
    <th />
    <th>1</th>
    <th />
    <th>0</th>
    <th />
    <th>37</th>
    <th />
    <th>0</th>
    </tr>

    <tr>
    <th>Harmonica|</th>
    <th />
    <th>0</th>
    <th />
    <th>0</th>
    <th />
    <th>0</th>
    <th />
    <th>20</th>
    </tr>
</table>
<p><br /> 
结果很显然易见，NBNN在声音分类方面还是很厉害的。更证明了声音分类和图像分类的相似之处。 
以后有时间的话，可以试试以下的东西:</p>

<ul>
  <li>可以在NBNN里不随机选取MFCC，而是选取更有代表性的</li>
  <li>使用 approximate kd-tree</li>
  <li>用图像分类里的 random forest算法试试看</li>
</ul>

<p>最后，感谢电驴，感谢python，感谢scipy，感谢voicebox 让哥在3天里搞定大作业。感谢尼玛操蛋的htk，要不是因为htk(本来好想做也语音编程系统的的)出不来结果我也不会换做这个来当speech recognition的大作业。</p>

</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">小逸</span></span>

      








  


<time datetime="2012-05-21T23:07:00-07:00" pubdate data-updated="true">May 21<span>st</span>, 2012</time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/分类/'>分类</a>, <a class='category' href='/blog/categories/计算机视觉/'>计算机视觉</a>, <a class='category' href='/blog/categories/音乐/'>音乐</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  <a href="http://twitter.com/share" class="twitter-share-button" data-url="http://kkx.github.com/blog/2012/05/21/yin-le-le-qi-sheng-yin-fen-lei/" data-via="" data-counturl="http://kkx.github.com/blog/2012/05/21/yin-le-le-qi-sheng-yin-fen-lei/" >Tweet</a>
  
  
  <div class="g-plusone" data-size="medium"></div>
  
  
    <div class="fb-like" data-send="true" data-width="450" data-show-faces="false"></div>
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2012/05/12/grammatical-evolution-wen-fa-suan-fa/" title="Previous Post: Grammatical evolution 文法算法">&laquo; Grammatical evolution 文法算法</a>
      
      
        <a class="basic-alignment right" href="/blog/2012/05/30/shu-ju-ji-bu-ping-heng-wen-ti/" title="Next Post: 数据集不平衡问题">数据集不平衡问题 &raquo;</a>
      
    </p>
  </footer>
</article>

  <section>
    <h1>Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
  </section>

</div>

<aside class="sidebar">
  
    
<section>
  <img src="http://gravatar.com/avatar/e67de7fa62d9665c4022a6a065353549" alt="Gravatar image" title="Gravatar Image" />
  <DIV ALIGN=left>I am not good enough for you</DIV>

  <p />
  </section>
  
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2012/12/02/guan-yu-knnhe-random-forestsde-gan-jue/">关于Knn和Random Forests的感觉</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/10/19/c-plus-plus-li-shi-yong-octave/">c++里使用octave</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/09/24/fast-approximate-nearest-neighbors-flann/">FAST APPROXIMATE NEAREST NEIGHBORS(FLANN)</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/09/16/ma-sai-ke-tu-pian-pin-jie/">马赛克图片拼接</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/09/10/gao-du-xiang-si-tu-pian-jian-ce-3perceptual-hash-phash-tu-pian-zhi-wen/">高度相似图片检测: 3 Perceptual Hash(phash) 图片指纹</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>Categories</h1>
      <ul id="category-list"><li><a href='/blog/categories/c-'>C++ (1)</a></li><li><a href='/blog/categories/gabor-filters'>Gabor filters (1)</a></li><li><a href='/blog/categories/google'>Google (1)</a></li><li><a href='/blog/categories/grammatical-evolution'>Grammatical evolution (1)</a></li><li><a href='/blog/categories/knn'>Knn (1)</a></li><li><a href='/blog/categories/knn-'>Knn, (1)</a></li><li><a href='/blog/categories/latex'>Latex (1)</a></li><li><a href='/blog/categories/numpy'>Numpy (1)</a></li><li><a href='/blog/categories/ocr'>Ocr (3)</a></li><li><a href='/blog/categories/octave'>Octave (1)</a></li><li><a href='/blog/categories/octopress'>Octopress (1)</a></li><li><a href='/blog/categories/python'>Python (3)</a></li><li><a href='/blog/categories/scipy'>Scipy (1)</a></li><li><a href='/blog/categories/svm'>Svm (1)</a></li><li><a href='/blog/categories/weka'>Weka (1)</a></li><li><a href='/blog/categories/不平衡数据集'>不平衡数据集 (1)</a></li><li><a href='/blog/categories/中文字图片生成'>中文字图片生成 (1)</a></li><li><a href='/blog/categories/中文字特征提取'>中文字特征提取 (1)</a></li><li><a href='/blog/categories/中文字符识别'>中文字符识别 (1)</a></li><li><a href='/blog/categories/分类'>分类 (4)</a></li><li><a href='/blog/categories/图像'>图像 (6)</a></li><li><a href='/blog/categories/机器学习'>机器学习 (2)</a></li><li><a href='/blog/categories/计算机视觉'>计算机视觉 (6)</a></li><li><a href='/blog/categories/随机森林'>随机森林 (1)</a></li><li><a href='/blog/categories/音乐'>音乐 (1)</a></li><li><a href='/blog/categories/马赛克'>马赛克 (1)</a></li><li><a href='/blog/categories/高度相似图片检测'>高度相似图片检测 (3)</a></li><li><a href='/blog/categories/高度相似性图片检测'>高度相似性图片检测 (1)</a></li></ul>
      </section>
<section>
最近读的书
<script type="text/javascript" src="http://www.douban.com/service/badge/Rabbby/?show=collection&amp;n=16&amp;columns=4&amp;hidelogo=yes&amp;cat=book|site" ></script>
</section>


<section>
my Last.fm
<a href="http://www.last.fm/user/kkx123456/?chartstyle=basic10"><img src="http://imagegen.last.fm/basic10/otracks/kkx123456.gif" border="0" /></a>
</section>






  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2012 - 小逸 -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'kkx';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://kkx.github.com/blog/2012/05/21/yin-le-le-qi-sheng-yin-fen-lei/';
        var disqus_url = 'http://kkx.github.com/blog/2012/05/21/yin-le-le-qi-sheng-yin-fen-lei/';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>



  <script type="text/javascript">
    (function() {
      var script = document.createElement('script'); script.type = 'text/javascript'; script.async = true;
      script.src = 'https://apis.google.com/js/plusone.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(script, s);
    })();
  </script>



  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
