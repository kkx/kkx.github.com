<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[名字]]></title>
  <link href="http://kkx.github.com/atom.xml" rel="self"/>
  <link href="http://kkx.github.com/"/>
  <updated>2012-05-22T02:31:48-07:00</updated>
  <id>http://kkx.github.com/</id>
  <author>
    <name><![CDATA[小逸]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[音乐乐器声音分类]]></title>
    <link href="http://kkx.github.com/blog/2012/05/21/yin-le-le-qi-sheng-yin-fen-lei/"/>
    <updated>2012-05-21T23:07:00-07:00</updated>
    <id>http://kkx.github.com/blog/2012/05/21/yin-le-le-qi-sheng-yin-fen-lei</id>
    <content type="html"><![CDATA[<p>音乐分类其实很早就有人做了，这些天在kaggle上有个<a href="http://www.kaggle.com/c/msdchallenge">Million Song Dataset Challenge</a> 非常火，上面有大量的数据可以让选手们通过底层，高层的和基于用户协作推荐的等等手段来对歌曲进行推荐. 这里我做的音乐声音分类是底层的, 而且我觉得一般的音乐文件要处理的东西太多了，节奏，速度什么的，在这里我只对4种乐器的声音进行分类: 钢琴，吉他，口琴，小提琴。</p>

<p>一般底层的声音，语音分类，speech recognition 使用无外乎<a href="MFCC">Mel-frequency cepstrum</a> 和 lpc analysis。 第二是个比较老的方法，而MFCC是我所用到的。可以把MFCCs对于好分类和识别的家伙们来说可以理解为对一段声音文件的descriptor，重点是这个descriptor非常discriminant. 在实验中，使用了matlab的voicebox里的melcepst函数，可以生成长度为12的数组，每个数组一般是一很小段声音的description，由于取样和设置的问题，MFCC所包含的声音长度是不一样的，在我的实验中，差不多连续1000个MFCC差不多是6秒钟的音频。 那4种声音来源分别是verycd上名家solo哈，不过要吐槽的是找了好多title是solo的，但是其实是是几种乐器和音的。每个类里取了6首左右的歌曲(20分钟左右)作为训练数据，提取出500k的MFCCs。</p>

<p>在实验中我使用了两个方法, 一种是在学校里老师讲的”常规”方法, 还有一种是用于图像分类的。总觉得在做底层分类的时候，图像识别和声音识别的步骤是差不多的。</p>

<ul>
  <li>Binary-split, SVM</li>
  <li>Naive Bayes Nearest Neighbor </li>
</ul>

<h2 id="binary-split--svm">Binary-split + SVM</h2>

<p>500k+的数据直接用来使用的话那就太夸张了，Binary-split+SVM这方法简单的来说是通过binary-split把500k的MFCC压缩成1000到2000个clusters，通过binary-split类似的数据会在一个小组里面。这种clustering算法里最有名的是k-means，不过k-means 速度实在是太悲剧了，虽然压缩损耗度要比binary-split少一些。 </p>

<p>通过binary-split数据给压缩到少许clusters里，这所有的clusters其实就是所谓的<a href="http://en.wikipedia.org/wiki/Codebook">codebook</a>。codebook在通讯里面非常用,往往在数据通讯里，特别是声音传输中，需要用到codebook把传输数据进行压缩，在接受点的那一端，通过decode来还原原始数据。像一般的手机通讯就是用到这个概念，所以说很多时候人们发现电话里的声音总不是特别像某个人，原因就是因为声音信息在传输的时候多少给损耗掉了。在实验中，每个声音段(通常是1000个MFCCs也就是6秒左右的声音)用codebook可以生成一个一个histogram: 把每个MFCC在binary-split树里跑一下，找到最相近的cluster，通过统计所有cluster里一个声音段落里不同的MFCCs所出现的次数来生成Histogram。</p>

<p>每个声音段所产生的histrogram就是所要用到用来训练SVM的数据。这里的svm是one-vs-all，所以说将有4个svm会训练出来，每个svm会应对每个类，而每个svm会长生出一个概率值，是只一个声音段是它所对应类的可能性。在测试中往往选取最高的可能性作为音频的class。</p>

<p>在测试中，以上的步骤都差不多，只是，不需要生成codebook，直接使用了就可以。这里要说的是，测试的音频长度不一定需要和训练的音频长度一样，只要每次生成的histogram是归一化的就行了。</p>

<table border="1" cellspacing="30" cellpadding="100">
    <tr>
    <th />
    <th />
    <th> Piano|</th>
    <th>          </th>
    <th> Guitar| </th>
    <th>          </th>
    <th> Violin| </th>
    <th />
    <th> Harmonica| </th>
    </tr>

    <tr>
    <th>Piano|</th>
    <th />
    <th>16</th>
    <th />
    <th>8</th>
    <th />
    <th>0</th>
    <th />
    <th>0</th>
    </tr>

    <tr>
    <th>Guitar|</th>
    <th />
    <th>4</th>
    <th />
    <th>12</th>
    <th />
    <th>20</th>
    <th />
    <th>4</th>
    </tr>
    
    <tr>
    <th>Violin|</th>
    <th />
    <th>0</th>
    <th />
    <th>0</th>
    <th />
    <th>20</th>
    <th />
    <th>4</th>
    </tr>

    <tr>
    <th>Harmonica|</th>
    <th />
    <th>0</th>
    <th />
    <th>0</th>
    <th />
    <th>0</th>
    <th />
    <th>16</th>
    </tr>
</table>

<p><br />
测试的时候每个类有20个case，从结果上来看，钢琴和吉他的识别不是很高，而且他们彼此有着很高互指。其实很大的原因是:当我们用codebook的时候，会对数据进行压缩，很多时候这个压缩会让比较discriminant的数据丢失。在这个实验中，钢琴和吉他的声音是比较相似的。</p>

<p><img class="center" src="http://kkx.github.com/images/histogram1.png" width="650" height="850" />
上面这个图是个histogram的分布图，通过随机选取每个类里的某一个训练的音频段生成的分布图，从途中可以看出，实际上通过codebook之后，吉他和钢琴的数据分布是非常耦合和相似的。所以，实验中对钢琴和吉他的分别度不高也有了依据。</p>

<h2 id="naive-bayes-nearest-neighbornbnn">Naive Bayes Nearest Neighbor(NBNN)</h2>
<p>实际上，在图像识别中，很多时候也是运用到了上面所讲的方法，通过codebook对图像所提取的key-points进行clusterization，之后通过第二层的分类器把codebook产出的histogram数组进行分类。所以我觉得NBNN应该也能运用到声音分类中来。 NBNN是最近以篇叫<a href="http://www.google.es/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;ved=0CFMQFjAA&amp;url=http%3A%2F%2Fwww.wisdom.weizmann.ac.il%2F~irani%2FPAPERS%2FInDefenceOfNN_CVPR08.pdf&amp;ei=d7G6T6yCKaOu0QX5_cD0Aw&amp;usg=AFQjCNGWk0lo_L6AEjgco6PPMUZ0YE-zOQ&amp;sig2=ZvwoYRICPitYbrkseMV8Bw">In Defense of Nearest-Neighbor Based Image Classification</a>的论文中看到的，该论文着重指出，codebook对数据损耗在无训练模型中的影响。 NBNN就是无训练模型(也叫no parametric?)， 优点就是不需要训练。。。还有一个优点是在分类里，NBNN用的是image-class距离，而不是image-image距离，这样的话，intravariance很高的类对它的影响不大。</p>

<p>在论文中如果我们使用的邻近邻居是1的话，算法简化成以下:</p>

<ol>
  <li>Compute MFCCs <script type="math/tex">d_i,...,d_n</script> of the query audio</li>
  <li><script type="math/tex">\forall d_i \forall C</script> compute the NN of <script type="math/tex">d_i</script> in <script type="math/tex">C</script>: <script type="math/tex">NN_C(d_i)</script></li>
  <li><script type="math/tex">C = arg min_c\sum_{i=1}^n</script> <script type="math/tex">\left \|d_i - NN_c(d_i)\right \|^2  </script></li>
</ol>

<p><img class="right" src="http://kkx.github.com/images/kd_tree.png" width="200" height="250" title="kt-tree" />
还有一点要说的是，在寻找最近邻居的时候，计算需求是相当高的，在原文里，作者用的是<a href="http://en.wikipedia.org/wiki/K-d_tree">kd-tree</a>,这样的能很快的找到最近的邻居。在这个实验的时候我用的scipy里kd-tree效率非常慢，后来才发现原来原作者是用的approximate kd-tree. </p>

<p>这个算法虽然简单，但是结果是惊人的不错:
使用所有的训练数据里的mfcc，每个测试音频有2000个MFCC，测试过程相当慢(好几个小时,如果使用approximate kd-tree的话应该能快好几个数量级)</p>

<table border="1" cellspacing="30" cellpadding="100">
    <tr>
    <th />
    <th />
    <th> Piano|</th>
    <th>          </th>
    <th> Guitar| </th>
    <th>          </th>
    <th> Violin| </th>
    <th />
    <th> Harmonica| </th>
    </tr>

    <tr>
    <th>Piano|</th>
    <th />
    <th>20</th>
    <th />
    <th>0</th>
    <th />
    <th>0</th>
    <th />
    <th>0</th>
    </tr>

    <tr>
    <th>Guitar|</th>
    <th />
    <th>0</th>
    <th />
    <th>20</th>
    <th />
    <th>1</th>
    <th />
    <th>0</th>
    </tr>
    
    <tr>
    <th>Violin|</th>
    <th />
    <th>0</th>
    <th />
    <th>0</th>
    <th />
    <th>19</th>
    <th />
    <th>0</th>
    </tr>

    <tr>
    <th>Harmonica|</th>
    <th />
    <th>0</th>
    <th />
    <th>0</th>
    <th />
    <th>0</th>
    <th />
    <th>20</th>
    </tr>
</table>

<p><br />
从数据集里随机在每个类中获取500个MFCC，每个音频400个MFCC</p>

<table border="1" cellspacing="30" cellpadding="100">
    <tr>
    <th />
    <th />
    <th> Piano|</th>
    <th>          </th>
    <th> Guitar| </th>
    <th>          </th>
    <th> Violin| </th>
    <th />
    <th> Harmonica| </th>
    </tr>

    <tr>
    <th>Piano|</th>
    <th />
    <th>20</th>
    <th />
    <th>0</th>
    <th />
    <th>0</th>
    <th />
    <th>0</th>
    </tr>

    <tr>
    <th>Guitar|</th>
    <th />
    <th>0</th>
    <th />
    <th>20</th>
    <th />
    <th>3</th>
    <th />
    <th>0</th>
    </tr>
    
    <tr>
    <th>Violin|</th>
    <th />
    <th>0</th>
    <th />
    <th>0</th>
    <th />
    <th>17</th>
    <th />
    <th>0</th>
    </tr>

    <tr>
    <th>Harmonica|</th>
    <th />
    <th>0</th>
    <th />
    <th>0</th>
    <th />
    <th>0</th>
    <th />
    <th>20</th>
    </tr>
</table>

<p><br />
最后是从每个类的训练数据中随机抽取30个MFCCs，每200个MFCC做音频测试数据的长度,测试数据是每个类40个，总使用的时间几秒而已</p>

<table border="1" cellspacing="30" cellpadding="100">
    <tr>
    <th />
    <th />
    <th> Piano|</th>
    <th>          </th>
    <th> Guitar| </th>
    <th>          </th>
    <th> Violin| </th>
    <th />
    <th> Harmonica| </th>
    </tr>

    <tr>
    <th>Piano|</th>
    <th />
    <th>35</th>
    <th />
    <th>5</th>
    <th />
    <th>2</th>
    <th />
    <th>0</th>
    </tr>

    <tr>
    <th>Guitar|</th>
    <th />
    <th>4</th>
    <th />
    <th>35</th>
    <th />
    <th>1</th>
    <th />
    <th>0</th>
    </tr>
    
    <tr>
    <th>Violin|</th>
    <th />
    <th>1</th>
    <th />
    <th>0</th>
    <th />
    <th>37</th>
    <th />
    <th>0</th>
    </tr>

    <tr>
    <th>Harmonica|</th>
    <th />
    <th>0</th>
    <th />
    <th>0</th>
    <th />
    <th>0</th>
    <th />
    <th>20</th>
    </tr>
</table>
<p><br /> 
结果很显然易见，NBNN在声音分类方面还是很厉害的。更证明了声音分类和图像分类的相似之处。 
以后有时间的话，可以试试以下的东西:</p>

<ul>
  <li>可以在NBNN里不随机选取MFCC，而是选取更有代表性的</li>
  <li>使用 approximate kd-tree</li>
  <li>用图像分类里的 random forest算法试试看</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Grammatical evolution 文法算法]]></title>
    <link href="http://kkx.github.com/blog/2012/05/12/grammatical-evolution-wen-fa-suan-fa/"/>
    <updated>2012-05-12T16:37:00-07:00</updated>
    <id>http://kkx.github.com/blog/2012/05/12/grammatical-evolution-wen-fa-suan-fa</id>
    <content type="html"><![CDATA[<p>Grammatical evolution 算法是一个遗传算法的分支，主要是通过遗传算法中的operators:crossover(杂交), mutation(变异)来查找最有解，而在grammatical evolution里最优解是以个方程或者一系列的代码块(executable program)。优秀的代码块往往能对目标解有很好的靠近。这个学术界的代表人物就要算是<a href="http://en.wikipedia.org/wiki/John_Koza">John Koza</a>, 他的<a href="http://www.genetic-programming.com/jkpdf/tr1314.pdf">Genetic Programming: A Paradigm for Genetically Breeding Populations of Computer Programs to Solve Problems</a>也是一本很好的reference。</p>

<p>GE算法主要通过<a href="http://en.wikipedia.org/wiki/Backus-Naur_form">BNF语法</a>对一个search space进行限制，这样的话能很好的对那些破坏语法规则的代码块进行剔除，大大减少了搜索空间的范围。在实际运用中，有两个主要概念: “genotype”和”phenotype。也就是基因和外貌，一个很好的例子就是你的外貌(眼睛颜色)取决语你的基因(DNA)，而通常基因和外貌是两层不一样的东西。 在GE算法里，phenotype就是我们所要的程序，而genotype是一串整数。通过这串整数的数值和他们所在的环境(也就是所有的语法规则)产生出来一系列的rules(代码)，最终这一连串的代码的就结果就是我们所在找的代码块。通过检验代码块的fitness(通常在找一个方程的时候会先行计算要找方程对于某些特定数值的预计结果，然后通过代码块和预定数值的数值结果差的大小来判断相似度, 变相的监督学习？)来决定他的’繁殖’能力，这样我们又回到了GA算法里的crossover和mutation。也就是说，在GE算法里，每个代码块是一个人口，通过不断的对一大群人口不停的结合和转变找到最优质的答案。</p>

<p>有必要讲一下genotype转化到phenotype这一过程，在这篇Neill的文章<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.45.3336&amp;rep=rep1&amp;type=pdf">Grammatical evolution</a>中有很好的解释。</p>

<p>同个这个idea很多GE算法的变种也相继出来了，<a href="http://arantxa.ii.uam.es/~alfonsec/docs/confint/iwinac05.pdf">Attribute Grammar Evolution</a>和<a href="http://www.cs.bham.ac.uk/~wbl/biblio/cache/http___arantxa.ii.uam.es__alfonsec_artint_ieeetec.pdf">Christiansen Grammar Evolution: grammatical evolution with semantics</a>(我老师写的¬¬) 都是对GE的改进，通过对语法上下文和语义的限制和检查加快了搜索的速度和搜索的结果。不过太多的限制也会是算法的效能下降哦。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[在octopress中使用latex]]></title>
    <link href="http://kkx.github.com/blog/2012/05/05/zai-octopresszhong-shi-yong-latex/"/>
    <updated>2012-05-05T13:38:00-07:00</updated>
    <id>http://kkx.github.com/blog/2012/05/05/zai-octopresszhong-shi-yong-latex</id>
    <content type="html"><![CDATA[<p>原文在<a href="http://kqueue.org/blog/2012/01/05/hello-world/">http://kqueue.org/blog/2012/01/05/hello-world/</a>。通过MathJax, 把latex打在网页上。
首先是在<code>source/_includes/custom/head.html</code>添加以下代码:</p>

<pre><code>&lt;script type="text/javascript"
        src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"&gt;
&lt;/script&gt;
</code></pre>

<p>在<code>_config.yml</code> 把markdown的引擎从<code>rdiscount</code>换成<code>kramdown</code>, 当然如果没有装的话装一下<code>gem install kramdown</code>。从现在开始就能通过 <code>$$</code>..<code> $$</code>(<code>$$</code>在单独的一行中，代码上下各留一空行)写latex啦
原文作者说好像会出现一些杂乱字符，你可以在<code>source/_includes/custom/head.html</code>添加以下代码来解决:</p>

<pre><code>&lt;script type="text/x-mathjax-config"&gt;
MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
          MathJax.InputJax.TeX.prefilterHooks.Add(function (data) {
                  data.math = data.math.replace(/^\s*&lt;!\[CDATA\[\s*((?:\n|.)*)\s*\]\]&gt;\s*$/m,"$1");
                    });
          });
&lt;/script&gt;
</code></pre>

<p>这里是一个例子<a href="http://en.wikipedia.org/wiki/Multivariate_normal_distribution">Multivariate normal distribution</a>:</p>

<script type="math/tex; mode=display">
f_x(x_1,...,x_k)=\frac{1}{(2\pi)^{k/2}|\Sigma|^{1/2}}exp(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu))
</script>

<pre><code>
$$
f_x(x_1,...,x_k)=\frac{1}{(2\pi)^{k\/2}|\Sigma|^{1\/2}}exp(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu))
$$

</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[numpy和matlab之间的数据交互]]></title>
    <link href="http://kkx.github.com/blog/2012/05/04/numpyhe-matlabzhi-jian-de-shu-ju-jiao-hu/"/>
    <updated>2012-05-04T18:03:00-07:00</updated>
    <id>http://kkx.github.com/blog/2012/05/04/numpyhe-matlabzhi-jian-de-shu-ju-jiao-hu</id>
    <content type="html"><![CDATA[<p>要让matlab把数据倒入倒python里很简单, 我试过直接保存倒2进制的文件里，但是通过用scipy.io.loadmat 这个方法读取的时候会报错。结果职能用粗糙的办法了，把文件存放在一个可读文件里:</p>

<pre><code>save -ascii "your.txt" yourMatrix 
</code></pre>

<p>在python里读取的时候用genfromtxt:</p>

<pre><code>from numpy import genfromtxt
m = genfromtxt('your.txt') 
</code></pre>

<p>想通过python把array寸在一个matlab能读取的文件里的方法也很简单:</p>

<pre><code>from numpy import savetxt
savetxt("your.txt", yourArray)
</code></pre>

<p>在matlab里直接load就行了:</p>

<pre><code>load -ascii your.txt newMatrixName
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[用nohup后台运行,用python 发提醒邮件]]></title>
    <link href="http://kkx.github.com/blog/2012/04/29/yong-python-fa-ti-xing-you-jian/"/>
    <updated>2012-04-29T01:09:00-07:00</updated>
    <id>http://kkx.github.com/blog/2012/04/29/yong-python-fa-ti-xing-you-jian</id>
    <content type="html"><![CDATA[<p>最近在学校的n电脑上跑数据，很多时候一个run要耗费好几个小时，ssh不知道为什么连一会后会自动断开，跑到一半程序就悲剧了。
在网上找了一会 发现一个神器:nohup, 用法超级简单: nohup comand
这样你的程序会后台运行，并且就算你ssh断开后都能继续跑着。nohup还提供给你一个nohup.log 你程序所有的output都会放在那个log里。</p>

<p>另外一个碰到的问题是，很多时候离开ssh后我都不知道程序跑完没，这里我用python搞了一个小程序:基于smtp发电子邮件。首先我用python的subprocess去跑数据程序，然后当数据程序跑完后发送一个邮件到我的邮箱里，这样我就能差不多“实时”的知道程序运行的情况了。</p>

<p>这是我发送邮件的小函数：</p>

<pre><code>#!/usr/bin/env python
# -*- coding: utf8 -*-
import smtplib
from email.mime.text import MIMEText

server = "smtp.gmail.com:587"
user_account="pythonsmtpalert@gmail.com"
password="密码"
mailto_list=["我的目标邮箱.com"]
def send_mail(to_list,sub,content):
        me="python stmp alert " +"&lt;pythonsmtpalert@gmail.com&gt;"
        msg = MIMEText(content)
        msg['Subject'] = sub
        msg['From'] = me
        msg['To'] = ";".join(mailto_list)
        try:
            s = smtplib.SMTP(server)
            s.starttls()  
            s.login(user_account,password)
            s.sendmail(me, to_list, msg.as_string())
            s.close()
            return True
        except Exception, e:
            print str(e)
            return False

if __name__ == '__main__':
    if send_mail(mailto_list,"Process accomplished","t你好ake a look the results!"):
        print "发送成功"
    else:
        print "发送失败"
</code></pre>

<p>server: 服务器地址
user_account:你的邮箱帐号
password:邮箱密码
mailto_list:目标邮箱
这里你的邮箱要和你服务器地址是一个牌子的，我这里用的是gmail，换别的邮箱的话得用别得邮箱得smtp服务器 </p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[根据bag of keypoints图片分类]]></title>
    <link href="http://kkx.github.com/blog/2012/04/20/gen-ju-bag-of-keypointstu-pian-fen-lei/"/>
    <updated>2012-04-20T02:41:00-07:00</updated>
    <id>http://kkx.github.com/blog/2012/04/20/gen-ju-bag-of-keypointstu-pian-fen-lei</id>
    <content type="html"><![CDATA[<p>最近看了一篇名叫<a href="http://www.xrce.xerox.com/index.php/content/download/16612/118527/file/willamowski.pdf">Categorizing nine visual classes using local appearance descriptors</a> 的论文，相当受启发，该论文以Information retrieval里<a href="http://en.wikipedia.org/wiki/Bag_of_words_model">bag of words</a>(以单词的出现的次数的矩阵来概括某篇文章)为基础,通过对图像所有的interest points用<a href="http://en.wikipedia.org/wiki/Harris_affine_region_detector">harris affine detector</a>来
产生一个bag of keypoints(用sift descriptor描述每个keypoints) 对图像进行描述。</p>

<p>不过一套训练数据里所有的keypoints的数量是相当大的，这里论文的另外一个看点就是用k-means对所有的keypoints进行归类，每个cluster之中保含类似的keypoints，而这时，每个图像里的keypoints 在每个cluster里的出现次数将会给统计并且生成一个bag of keypoints. </p>

<p>通过naive bayes或svm 进行训练，在论文里分类的结果还不错.
有几个我觉得也许可以改进的地方:</p>

<blockquote>
  <p>1 在原论文里：每种图像生成的keypoints的数量是不同的，为了避免bias作者在clustering的时候在每类图像里随机选了5000个keypoints，我觉得如果选的时候可以把stop words的概念加进去，每个class都有的keypoint去除掉的话应该能增加discrimination.</p>
</blockquote>

<blockquote>
  <p>2 在测试的时候我觉得如果一个keypoint离2个以上的cluster距离都差不多的话，应该可以把它当作IR里的‘生词’一样忽略掉.
感觉以上这两点应该能对算法有一个改进，以后有空得研究下。</p>
</blockquote>

<p>还有在论文里作者在做测试的时候没有使用no-object的图像进行训练和测试，我觉得如果加进去的话，结果应该会差一个档次。</p>

<p>参考:
http://en.wikipedia.org/wiki/Bag_of_words_model_in_computer_vision.</p>

<p>这里是<a href="http://videolectures.net/lmcv04_dance_vcbk/">作者介绍算法的视频</a>,解释的相当不错，不过好像视频后半部分看不了。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hello World]]></title>
    <link href="http://kkx.github.com/blog/2012/04/15/hello-world/"/>
    <updated>2012-04-15T17:28:00-07:00</updated>
    <id>http://kkx.github.com/blog/2012/04/15/hello-world</id>
    <content type="html"><![CDATA[<p>HELLO WORLD!!!!</p>
]]></content>
  </entry>
  
</feed>
